# Voice Command System ğŸ¤

A **wake-word detection system** ("Hey AI") using **MFCC features + RNN (LSTM)**.  

## ğŸš€ Features
- Detects custom wake word in real-time
- Uses MFCC audio features
- RNN (LSTM) for sequence classification

## ğŸ› ï¸ Tech Stack
- Python
- TensorFlow/Keras
- Librosa (MFCC extraction)
- SoundDevice (real-time audio input)

## ğŸ“‚ Project Structure

voice-command-system/
â”‚â”€â”€ data/ # dataset
â”‚ â”œâ”€â”€ hey_ai/ # "Hey AI" samples
â”‚ â”œâ”€â”€ other/ # background/noise
â”‚â”€â”€ models/ # trained model
â”‚â”€â”€ train.py # training script
â”‚â”€â”€ detect.py # real-time detection
â”‚â”€â”€ requirements.txt # dependencies
â”‚â”€â”€ README.md # docs


## ğŸ“Š Dataset
- Record samples of yourself saying **"Hey AI"** (~100+ samples).
- Collect background/noise/random speech (~200+ samples).
- Save in `data/hey_ai/` and `data/other/`.

## ğŸ“¦ Installation
```bash
git clone https://github.com/your-username/voice-command-system.git
cd voice-command-system
pip install -r requirements.txt
ğŸ”§ Usage

Train the model:
python train.py
(model will be saved in models/hey_ai_rnn.h5)


Run detection:

python detect.py
Say "Hey AI" into your mic ğŸ¤

ğŸ™Œ Acknowledgments

Librosa:for audio processing
TensorFlow: for deep learning


